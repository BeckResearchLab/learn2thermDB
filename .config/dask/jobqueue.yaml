jobqueue:

  slurm:
    name: learn2therm-worker

    # Dask worker options
    cores: 1                 # Total number of cores per job
    job_cpu: 6
    memory: '5G'                # Total amount of memory per job
    processes: 1                # Number of Python processes per job

    interface: null             # Network interface to use like eth0 or ib0
    death-timeout: 60           # Number of seconds to wait if a worker can not find a scheduler
    local-directory: /mmfs1/gscratch/cheme/usr/evankomp/repos/learn2therm/       # Location of fast local storage like /scratch or $TMPDIR

    # SLURM resource manager options
    shebang: "#!/usr/bin/env bash"
    queue: compute
    account: cheme
    walltime: '01:30:00'
    job-mem: null
    log-directory: './logs/dask/'
    
    job_extra_directives: ['--nodes=1', '--ntasks-per-node=1', '--hint=multithread']
    worker_extra_args: ["--lifetime", "85m", "--lifetime-stagger", "2m"]
    job_script_prologue: ["source ~/.bashrc", "conda activate learn2therm"]    
    
    # Scheduler options
    scheduler-options: {}

