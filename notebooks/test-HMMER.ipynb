{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing pyhmmer work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system dependecies\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "import time\n",
    "from typing import Union\n",
    "\n",
    "# library dependencies\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import duckdb as ddb\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "import pyhmmer\n",
    "\n",
    "# local dependencies\n",
    "import learn2therm.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.path.abspath(\"/Users/humoodalanzi/pfam/proteins copy/*.parquet\")\n",
    "HMM_PATH = '/Users/humoodalanzi/pfam/Pfam-A.hmm'  # ./Pfam-A.hmm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing ground for loading funciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stolen from Evan's t1.0 scripts\n",
    "with tempfile.TemporaryDirectory(dir='./') as tmpdir:\n",
    "    # Establishing a connection with Duck DB\n",
    "    conn = ddb.connect(tmpdir+'proteins.db', read_only=False)\n",
    "    # Making a SQL table\n",
    "    conn.execute(\"CREATE TABLE proteins AS SELECT * FROM read_parquet('../data/uniprot_chunk_0.parquet')\")\n",
    "    # Committing DB\n",
    "    conn.commit()\n",
    "\n",
    "     # get some test proteins to run resource test alignment on\n",
    "    # considering the max protein length\n",
    "    query_proteins = conn.execute(\n",
    "        f\"\"\"SELECT pid, protein_seq, LENGTH(protein_seq) AS len FROM proteins \n",
    "        WHERE len<=250\n",
    "        ORDER BY RANDOM()\n",
    "        LIMIT 1000\n",
    "        \"\"\").df()\n",
    "    subject_proteins = conn.execute(\n",
    "        f\"\"\"SELECT pid, protein_seq, LENGTH(protein_seq) AS len FROM proteins \n",
    "        WHERE len<=250\n",
    "        ORDER BY RANDOM()\n",
    "        LIMIT 1000\n",
    "        \"\"\").df()\n",
    "\n",
    "    # get some metadata about taxa protein join\n",
    "    # protein total counts per organism was tracked in s0.3\n",
    "    # but lets recompute that data considering a max protien length\n",
    "    protein_counts = conn.execute(\n",
    "        f\"\"\"SELECT taxid, COUNT(*) AS n_proteins\n",
    "        FROM proteins\n",
    "        WHERE LENGTH(protein_seq)<=250\n",
    "        GROUP BY taxid\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>protein_seq</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I3R7V8</td>\n",
       "      <td>MPSEKEKMLAGELYDASDPELVMERKRARRLTRRFNASDETESLRR...</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L0JM53</td>\n",
       "      <td>MIGSDVVVAGSALAIAVAVGLVAHEWSHAAVLRLARVEYAVSYFPG...</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I3R9Q8</td>\n",
       "      <td>MYEHILVPTDGSETAEYAVDQAVDIASKYGSTVHALYVIDVDATSY...</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L0JY84</td>\n",
       "      <td>MKDVKLDPSEESTYECFDCGTVVVSATAPGRCPSCGADMRNRATPLE</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I3R1G7</td>\n",
       "      <td>MANGKYAARKLKKDRQKRRWSDSEYARRERGLGKKSDPLEGAPQGR...</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>A0A1L3Q032</td>\n",
       "      <td>MKYVKEFVKLAKSDLKSSVVLYENKCYPQSIFFFAQSVEKANKALA...</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>D2RQ33</td>\n",
       "      <td>MRKSGTWMTIWDDRILETLRKEGGKPVGELAEEDGIRISHSSVSRR...</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>A0A0A7GGQ8</td>\n",
       "      <td>MPLFLTRKAIEEVDVGDVIEVHADDPSARKDIPEWAERAGHKVLSV...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>A0A650CYC0</td>\n",
       "      <td>MPTIHLSIPEGMYEELRKKAEDMGIQITDLVKFYIRQGMEKEEEGE...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>M0B9M0</td>\n",
       "      <td>MAKSQSSQQNAAHGQLLSLLEGRPCPACADGELERDRYKGNRAVVC...</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pid                                        protein_seq  len\n",
       "0        I3R7V8  MPSEKEKMLAGELYDASDPELVMERKRARRLTRRFNASDETESLRR...  185\n",
       "1        L0JM53  MIGSDVVVAGSALAIAVAVGLVAHEWSHAAVLRLARVEYAVSYFPG...  149\n",
       "2        I3R9Q8  MYEHILVPTDGSETAEYAVDQAVDIASKYGSTVHALYVIDVDATSY...  154\n",
       "3        L0JY84    MKDVKLDPSEESTYECFDCGTVVVSATAPGRCPSCGADMRNRATPLE   47\n",
       "4        I3R1G7  MANGKYAARKLKKDRQKRRWSDSEYARRERGLGKKSDPLEGAPQGR...  142\n",
       "..          ...                                                ...  ...\n",
       "995  A0A1L3Q032  MKYVKEFVKLAKSDLKSSVVLYENKCYPQSIFFFAQSVEKANKALA...  193\n",
       "996      D2RQ33  MRKSGTWMTIWDDRILETLRKEGGKPVGELAEEDGIRISHSSVSRR...  103\n",
       "997  A0A0A7GGQ8  MPLFLTRKAIEEVDVGDVIEVHADDPSARKDIPEWAERAGHKVLSV...   61\n",
       "998  A0A650CYC0  MPTIHLSIPEGMYEELRKKAEDMGIQITDLVKFYIRQGMEKEEEGE...  101\n",
       "999      M0B9M0  MAKSQSSQQNAAHGQLLSLLEGRPCPACADGELERDRYKGNRAVVC...   59\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>protein_seq</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A1I0FQE4</td>\n",
       "      <td>MDVTQIGLGATLLVIGTLTLIGPATLATGPLAYLVTGSTLVVTVAA...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A1I0M298</td>\n",
       "      <td>MGFGSYDESEQQEQTTSDEDVEAVNVHENDHEGKLSFESDLSTDEL...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A0Q2QPZ4</td>\n",
       "      <td>MYKIKDEWGEFLVRLARRAIEEYVRNGRTIKPPEDTPPQLWERMGV...</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A0F8FH29</td>\n",
       "      <td>MTRFIKYHPRSNTYVIEKRAFLEEDLTLDGNVIVGPEVKFWKNLTV...</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B8D531</td>\n",
       "      <td>MNRVYVTVLATLLIIVGLLLGASMWLDILRANTYVDTGELDWEIVE...</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>A0A1H9YYW1</td>\n",
       "      <td>MNNIEEMIQKAVELQANGLVTGQIANELNVSRETVTWLLTRSKKDV...</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>L0JKK2</td>\n",
       "      <td>MGTHVLVPLDGSSQAWAAFDHAVSNHDGGRITTLHVVDPMAGVYSD...</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>L0JZ77</td>\n",
       "      <td>MCVSSRMPITVVQLTLSALAAVFAFITAVYGRLNYADGELDRQKKI...</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>L0JZQ8</td>\n",
       "      <td>MTVFALLRVTPITDDDATEDVAAAIDALEEYDVEYETTPLATTLEA...</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>A0A660HS56</td>\n",
       "      <td>MFRLTIVYGNKASQDFTGSWGFATLIQTNYETLLFDTGWDGPLLLE...</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pid                                        protein_seq  len\n",
       "0    A0A1I0FQE4  MDVTQIGLGATLLVIGTLTLIGPATLATGPLAYLVTGSTLVVTVAA...   58\n",
       "1    A0A1I0M298  MGFGSYDESEQQEQTTSDEDVEAVNVHENDHEGKLSFESDLSTDEL...   60\n",
       "2    A0A0Q2QPZ4  MYKIKDEWGEFLVRLARRAIEEYVRNGRTIKPPEDTPPQLWERMGV...  204\n",
       "3    A0A0F8FH29  MTRFIKYHPRSNTYVIEKRAFLEEDLTLDGNVIVGPEVKFWKNLTV...  142\n",
       "4        B8D531  MNRVYVTVLATLLIIVGLLLGASMWLDILRANTYVDTGELDWEIVE...  225\n",
       "..          ...                                                ...  ...\n",
       "995  A0A1H9YYW1  MNNIEEMIQKAVELQANGLVTGQIANELNVSRETVTWLLTRSKKDV...  203\n",
       "996      L0JKK2  MGTHVLVPLDGSSQAWAAFDHAVSNHDGGRITTLHVVDPMAGVYSD...  146\n",
       "997      L0JZ77  MCVSSRMPITVVQLTLSALAAVFAFITAVYGRLNYADGELDRQKKI...  195\n",
       "998      L0JZQ8  MTVFALLRVTPITDDDATEDVAAAIDALEEYDVEYETTPLATTLEA...  104\n",
       "999  A0A660HS56  MFRLTIVYGNKASQDFTGSWGFATLIQTNYETLLFDTGWDGPLLLE...  219\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_proteins"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in theory, I could sample the .parquet files and create a df out of them for loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goal to make this function\n",
    "def load_protein_data(database, **kwargs):\n",
    "    \"\"\"\n",
    "    Load the protein sequences and associated taxonomic information from the input CSV files\n",
    "    for DB version 1.0, or from the input Parquet files for DB version 1.1.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    database : _type_\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting the pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stolen from Evan's t1.0 scripts\n",
    "with tempfile.TemporaryDirectory(dir='../tmp/') as tmpdir:\n",
    "    # Establishing a connection with Duck DB\n",
    "    conn = ddb.connect(tmpdir+'proteins.db', read_only=False)\n",
    "    # Making a SQL table\n",
    "    conn.execute(f\"CREATE TABLE proteins AS SELECT * FROM read_parquet('../data/uniprot_chunk_0.parquet')\")\n",
    "    # Committing DB\n",
    "    conn.commit()\n",
    "\n",
    "    # get some test proteins to run resource test alignment on\n",
    "    # considering the max protein length\n",
    "    query_proteins = conn.execute(\n",
    "        \"\"\"SELECT pid, protein_seq, LENGTH(protein_seq) AS len FROM proteins \n",
    "        WHERE len<=250\n",
    "        ORDER BY RANDOM()\n",
    "        LIMIT 1000\n",
    "        \"\"\").df()\n",
    "\n",
    "    # get some metadata about taxa protein join\n",
    "    # protein total counts per organism was tracked in s0.3\n",
    "    # but lets recompute that data considering a max protien length\n",
    "    protein_counts = conn.execute(\n",
    "        \"\"\"SELECT taxid, COUNT(*) AS n_proteins\n",
    "        FROM proteins\n",
    "        WHERE LENGTH(protein_seq)<=250\n",
    "        GROUP BY taxid\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>protein_seq</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M0ATD1</td>\n",
       "      <td>MSKISRFTGKVVTLAKNAVGDRGESAAPQGGSGFADYAVVSLHCLR...</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A238UTT8</td>\n",
       "      <td>MPLLQFDTTLTLSPSDRRAFAERVTDVYTDEMATERGHVAVTIRER...</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A0A7GJ53</td>\n",
       "      <td>MLVTTGVCKSFGNHEVLKGIDFRVAPGEFAAIFAPSGSGKTTLLNI...</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A0K1ISF3</td>\n",
       "      <td>MTETWDSAGYIASSRYRLAVCRYLSEHGSGLPSRIAAETDLAQPHV...</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A830FPK4</td>\n",
       "      <td>MANLFGASLSLVLVVAGVALCIAEAFAPGAHFVVIGVALLAAGLAG...</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>E4NUJ6</td>\n",
       "      <td>MGKSSTSPSRRGGKGPKIERVAERYSITGLGDELVERWRGDQGEQE...</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>I3R8N2</td>\n",
       "      <td>MTVRLRTVTESDLPVIRTLYEPFVEETAITFAYDPPSVTDLESKLE...</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>D3SUA1</td>\n",
       "      <td>METVAVLNAIVDNLIEMNEYFSGVATGEGAAPLLMIAGTLLVVFSL...</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>O59571</td>\n",
       "      <td>MYKIVTVKDVVRIPPRMFTMDPKEAAMLVLRDTYEGTYDRDEGVIL...</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>O57891</td>\n",
       "      <td>MIHVGTCGFCEAREKYFKDFDAVEVQQTFYKVLQEKTLERWRKKAP...</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pid                                        protein_seq  len\n",
       "0        M0ATD1  MSKISRFTGKVVTLAKNAVGDRGESAAPQGGSGFADYAVVSLHCLR...  219\n",
       "1    A0A238UTT8  MPLLQFDTTLTLSPSDRRAFAERVTDVYTDEMATERGHVAVTIRER...  123\n",
       "2    A0A0A7GJ53  MLVTTGVCKSFGNHEVLKGIDFRVAPGEFAAIFAPSGSGKTTLLNI...  220\n",
       "3    A0A0K1ISF3  MTETWDSAGYIASSRYRLAVCRYLSEHGSGLPSRIAAETDLAQPHV...  225\n",
       "4    A0A830FPK4  MANLFGASLSLVLVVAGVALCIAEAFAPGAHFVVIGVALLAAGLAG...  190\n",
       "..          ...                                                ...  ...\n",
       "995      E4NUJ6  MGKSSTSPSRRGGKGPKIERVAERYSITGLGDELVERWRGDQGEQE...  206\n",
       "996      I3R8N2  MTVRLRTVTESDLPVIRTLYEPFVEETAITFAYDPPSVTDLESKLE...  201\n",
       "997      D3SUA1  METVAVLNAIVDNLIEMNEYFSGVATGEGAAPLLMIAGTLLVVFSL...   64\n",
       "998      O59571  MYKIVTVKDVVRIPPRMFTMDPKEAAMLVLRDTYEGTYDRDEGVIL...  188\n",
       "999      O57891  MIHVGTCGFCEAREKYFKDFDAVEVQQTFYKVLQEKTLERWRKKAP...  240\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_proteins"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lesson here is that I shouldn't do maby parquets w/o Hyak. Need to figure out to use vscode with Hyak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefetch_targets(hmms_path: str):\n",
    "    \"\"\"\n",
    "    Prefetch HMM profiles from a given HMM database.\n",
    "    Parameters\n",
    "    ----------\n",
    "    hmms_path : str\n",
    "        Path to the HMM database.\n",
    "    Returns\n",
    "    -------\n",
    "    targets : pyhmmer.plan7.OptimizedProfileBlock\n",
    "        The HMM profiles loaded from the database.\n",
    "    \"\"\"\n",
    "    # amino acid alphabet and prefetched inputs\n",
    "    amino_acids = pyhmmer.easel.Alphabet.amino()\n",
    "    optimized_profiles = list(pyhmmer.plan7.HMMPressedFile(hmms_path))\n",
    "    targets = pyhmmer.plan7.OptimizedProfileBlock(\n",
    "        amino_acids, optimized_profiles)\n",
    "    return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sequences_to_fasta(\n",
    "        sequences: pd.core.frame.DataFrame,\n",
    "        inputname: str = \"input\"):\n",
    "    \"\"\"\n",
    "    Returns a list of SeqRecord objects and creates a corresponding input Fasta of them\n",
    "    Parameters:\n",
    "    ------------\n",
    "    sequences : pandas.core.frame.DataFrame\n",
    "        a dataframe with string amino acid sequences in a 'protein_seq' column\n",
    "    input name : str, default = 'input'\n",
    "        a name for the input fasta file\n",
    "    Returns:\n",
    "    ------------\n",
    "    file : TextIOWrapper\n",
    "        the input fasta file created from the list of SeqRecord objects\n",
    "    Raises\n",
    "    -------\n",
    "    ValueError :\n",
    "        if the input dataframe is empty\n",
    "    AttributeError :\n",
    "        if any of the sequences are invalid\n",
    "    \"\"\"\n",
    "    # ensure input file has .fasta extension\n",
    "    if not inputname.endswith('.fasta'):\n",
    "        inputname = f\"{os.path.splitext(inputname)[0]}.fasta\"\n",
    "\n",
    "    # check if input is empty\n",
    "    if sequences.empty:\n",
    "        raise ValueError(\"Input dataframe is empty\")\n",
    "\n",
    "    # check if sequences are valid\n",
    "    for seq in sequences['protein_seq']:\n",
    "        try:\n",
    "            Seq(seq)\n",
    "        except BaseException as exc:\n",
    "            raise AttributeError(\"Invalid sequence\") from exc\n",
    "\n",
    "    # function\n",
    "    records = []\n",
    "    for index, seq in sequences.itertuples():\n",
    "        try:\n",
    "            record = SeqRecord(Seq(seq), id=str(index))\n",
    "            records.append(record)\n",
    "        except AttributeError as exc:\n",
    "            raise AttributeError(f\"Invalid sequence: {seq}\") from exc\n",
    "\n",
    "    # raise error if seq not valid\n",
    "    if not records:\n",
    "        raise AttributeError(\"No valid sequences found in input\")\n",
    "\n",
    "    with open(inputname, \"w\", encoding=\"utf-8\") as file:\n",
    "        SeqIO.write(records, file, \"fasta\")\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pyhmmer(\n",
    "        input_file: str,\n",
    "        hmms_path: str,\n",
    "        prefetch: bool = False,\n",
    "        output_file: str = None,\n",
    "        cpu: int = 4,\n",
    "        eval_con: float = 1e-10):\n",
    "    \"\"\"\n",
    "    Run HMMER's hmmscan program on a set of input sequences using with HMMs from a database.\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_file : str\n",
    "        Path to the input sequence file.\n",
    "    hmms_path : str\n",
    "        Path to the HMM database.\n",
    "    prefetch : bool, optional\n",
    "        Specifies how the HMM are stored in meomry.\n",
    "    output_file : str, optional\n",
    "        Path to the output file if the users wants to write the file.\n",
    "    cpu : int, optional\n",
    "        The number of CPUs to use. Default is 4.\n",
    "    eval_con : float, optional\n",
    "        E-value threshold for domain reporting. Default is 1e-10.\n",
    "    Returns\n",
    "    -------\n",
    "    all_hits : pyhmmer.plan7.TopHits or domtblout file\n",
    "        If the output_file has a name, it will be written to a domtblout file.\n",
    "        Otherwise, the user will get a list of pyhmmeer TopHits objects.\n",
    "    Notes\n",
    "    -----\n",
    "    This function runs HMMER's hmmscan program on a set of input sequences\n",
    "    using HMMs from a given database.\n",
    "    The function supports two modes: normal mode and prefetching mode.\n",
    "    In normal mode, the HMMs are pressed and stored in a directory before execution.\n",
    "    In prefetching mode, the HMMs are kept in memory for faster search.\n",
    "    \"\"\"\n",
    "    # ensure input file has .fasta extension\n",
    "    if not input_file.endswith('.fasta'):\n",
    "        input_file = f\"{os.path.splitext(input_file)[0]}.fasta\"\n",
    "\n",
    "    # ensure output_file has .domtblout extension\n",
    "    if not output_file.endswith('.domtblout'):\n",
    "        output_file = f\"{os.path.splitext(output_file)[0]}.domtblout\"\n",
    "\n",
    "    # HMM profile modes\n",
    "    if prefetch:\n",
    "        targets = prefetch_targets(hmms_path)\n",
    "    else:\n",
    "        targets = pyhmmer.plan7.HMMFile(\"../data/pfam/.h3m\")\n",
    "\n",
    "    # HMMscan execution with or without saving output to file\n",
    "    with pyhmmer.easel.SequenceFile(input_file, digital=True) as seqs:\n",
    "        all_hits = list(pyhmmer.hmmer.hmmscan(seqs, targets, cpus=cpu, E=eval_con))\n",
    "        # check if we should save the output\n",
    "        if output_file is not None:\n",
    "            with open(output_file, \"wb\") as dst:\n",
    "                for i, hits in enumerate(all_hits):\n",
    "                    hits.write(dst, format=\"domains\", header=i == 0)\n",
    "\n",
    "    return all_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pyhmmer(all_hits):\n",
    "    \"\"\"\n",
    "    Parses the TopHit pyhmmer object getting the query and accession IDs and saves to a DataFrame\n",
    "    Parameters\n",
    "    ----------\n",
    "    all_hits : list\n",
    "        A list of TopHit objects from pyhmmer.\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A dataframe containing the query and accession IDs.\n",
    "    \"\"\"\n",
    "    # initialize an empty dictionary to store the data\n",
    "    parsed_hits = {}\n",
    "\n",
    "    # iterate over each protein hit\n",
    "    for top_hits in all_hits:\n",
    "        for hit in top_hits:\n",
    "            # extract the query and accession IDs and decode the query ID\n",
    "            query_id = hit.hits.query_name.decode('utf-8')\n",
    "            accession_id = hit.accession.decode('utf-8')\n",
    "\n",
    "            # if the query_id already exists in the dictionary, append the accession_id\n",
    "            # to the existing value\n",
    "            if query_id in parsed_hits:\n",
    "                parsed_hits[query_id].append(accession_id)\n",
    "            # otherwise, create a new key-value pair in the dictionary\n",
    "            else:\n",
    "                parsed_hits[query_id] = [accession_id]\n",
    "\n",
    "    # create the DataFrame from the dictionary and convert list of accession IDs to string\n",
    "    df = pd.DataFrame(parsed_hits.items(), columns=[\"query_id\", \"accession_id\"])\n",
    "    df[\"accession_id\"] = df[\"accession_id\"].apply(lambda x: ';'.join(x))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_function(chunk_index, sequences, which, wakeup=None):\n",
    "    \"\"\"\n",
    "    A wrapping function that runs and parses pyhmmer in chunks\n",
    "    Parameters\n",
    "    ----------\n",
    "    chunk_index : int\n",
    "        number of sequences chunks\n",
    "    sequences : str\n",
    "        a list of dataframe containing protein sequences\n",
    "    \"\"\"\n",
    "    # we want to wait for execution to see if this worker is actually being used\n",
    "    # or if it is in the process of being killed\n",
    "    if wakeup is not None:\n",
    "        time.sleep(wakeup)\n",
    "    \n",
    "    # define paths for input and output files\n",
    "    input_file_path = f\"./results/{which}_input_{chunk_index}\"\n",
    "    output_file_path = f\"./results/{which}_output_{chunk_index}\"\n",
    "\n",
    "    # convert sequences to FASTA files\n",
    "    save_sequences_to_fasta(sequences, input_file_path)\n",
    "\n",
    "    # run HMMER via pyhmmer\n",
    "    hits = run_pyhmmer(\n",
    "        input_file=input_file_path,\n",
    "        hmms_path=PFAM_PATH,\n",
    "        prefetch=True,\n",
    "        output_file=output_file_path,\n",
    "        cpu=1,\n",
    "        eval_con=1e-5)\n",
    "\n",
    "    # Parse pyhmmer output and save to CSV file\n",
    "    accessions_parsed = parse_pyhmmer(all_hits=hits)\n",
    "    accessions_parsed.to_csv(\n",
    "        f\"./results/{which}_result_{chunk_index}.csv\",\n",
    "        index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn2therm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e8cd9fa205d578fad3090913ce994f268d54856e8861905dcf5c79a0f84f4591"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
